{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c7a2e4-a544-45a1-9c6a-723dd8ffbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from aaai_experiments import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f850b3-7d83-44f6-861f-2e31b73259d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:\\\\Users\\\\User\\\\Jupyter Projects\\\\Research_2\\\\Datasets'\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c0710-9332-47f7-a99e-eaf0b5852944",
   "metadata": {},
   "source": [
    "## A*, A* incremental, and REACH evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeca0399-abbd-465c-8ed8-66f1b41cb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for `load_and_preprocess_log`\n",
    "df_name = 'bpi_2012.csv'\n",
    "min_len = 80\n",
    "max_len = None\n",
    "n_traces = None\n",
    "random_seed = 304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ee4afa-7ccf-4442-9a00-eb6ce1ba8774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, map_dict = load_and_preprocess_log(df_name, min_len=min_len, max_len=max_len, n_traces=n_traces, random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b596af34-2d72-429b-b10d-d964c75ca6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for `compare_search_algorithms`\n",
    "n_train_traces = 10\n",
    "n_test_traces = None\n",
    "allow_intersection = False\n",
    "read_model_from_file = False\n",
    "model_path = 'prAm6.txt'\n",
    "activity_mapping_dict = map_dict\n",
    "only_return_model = False\n",
    "algorithms=['astar_extended']\n",
    "time_limit=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c762d88-d07e-4dba-88d7-76181e0ee33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_search_algorithms(\n",
    "    df=df,\n",
    "    df_name=df_name,\n",
    "    n_train_traces=n_train_traces,\n",
    "    n_test_traces=n_test_traces,\n",
    "    allow_intersection=allow_intersection,\n",
    "    read_model_from_file=read_model_from_file,\n",
    "    model_path=model_path,\n",
    "    activity_mapping_dict=activity_mapping_dict,\n",
    "    only_return_model=only_return_model,\n",
    "    algorithms=algorithms,\n",
    "    time_limit=time_limit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de8cb9d-ce17-4df6-99f7-e1f0bc606a2f",
   "metadata": {},
   "source": [
    "## Running Horizon (+ heuristics) evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3e7771-bcc2-4394-ba81-1b964903c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = 'bpi_2012.csv'\n",
    "model_path = ''\n",
    "n_train_traces = 10\n",
    "n_test_traces = None\n",
    "window_lengths_lst = [15, 30, 50]\n",
    "n_final_markings_lst = [1]\n",
    "min_len = 80\n",
    "max_len = None\n",
    "use_heuristics = True \n",
    "read_model_from_file = False\n",
    "allow_intersection = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "590b5d08-e031-4eb1-b8fc-e28eb183c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compare_window_based_baselines(\n",
    "    df_name=df_name,\n",
    "    n_train_traces=n_train_traces,\n",
    "    n_test_traces=n_test_traces,\n",
    "    window_lengths_lst=window_lengths_lst,\n",
    "    n_final_markings_lst=n_final_markings_lst,\n",
    "    min_len=min_len,\n",
    "    max_len=max_len,\n",
    "    use_heuristics=use_heuristics,\n",
    "    read_model_from_file=read_model_from_file,\n",
    "    model_path=model_path,\n",
    "    allow_intersection=allow_intersection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a560c1c-8611-49dc-8ff5-bf57a5e827c3",
   "metadata": {},
   "source": [
    "## Video Datasets evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e94d5ea-588f-45ea-92f7-15c58d2c7054",
   "metadata": {},
   "source": [
    "### Our approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba45a7d3-47e3-4e93-b2dc-6be385d3f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_traces = 10\n",
    "n_test_traces = None\n",
    "window_lengths_lst = [20]\n",
    "n_final_markings_lst = [1]\n",
    "use_heuristics = True \n",
    "allow_intersection = False\n",
    "random_seed=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c31982c-e819-445e-8750-fb487d529fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path and file names\n",
    "df_path = r'C:\\Users\\User\\Jupyter Projects\\Research_2\\Datasets\\Long_Traces'\n",
    "df_names = ['gtea_target.pkl', '50salads_target.pkl', 'breakfast_target.pkl']\n",
    "\n",
    "# Parameters for different datasets\n",
    "dataset_params = {\n",
    "    'gtea_target.pkl': 10,\n",
    "    '50salads_target.pkl': 10,\n",
    "    'breakfast_target.pkl': 15    \n",
    "}\n",
    "\n",
    "# Loop over each dataset\n",
    "for df_name in df_names:\n",
    "    print(f\"Processing dataset: {df_name}\")\n",
    "    \n",
    "    # Process the pickle file\n",
    "    df = process_pickle_file(os.path.join(df_path, df_name))\n",
    "    \n",
    "    # Adjust the number of training traces based on the dataset\n",
    "    n_train_traces = dataset_params[df_name]\n",
    "    \n",
    "    # Call the compare function with the processed DataFrame\n",
    "    res = compare_window_based_baselines(\n",
    "        df_name=df,\n",
    "        n_train_traces=n_train_traces,\n",
    "        n_test_traces=n_test_traces,\n",
    "        window_lengths_lst=window_lengths_lst,\n",
    "        n_final_markings_lst=n_final_markings_lst,\n",
    "        use_heuristics=use_heuristics,\n",
    "        allow_intersection=allow_intersection,\n",
    "        random_seed=random_seed\n",
    "    )\n",
    "    \n",
    "    # Define the path to save the results\n",
    "    result_save_path = os.path.join(df_path, f\"{df_name.split('_')[0]}_results.csv\")\n",
    "    \n",
    "    # Save the results after processing the dataset\n",
    "    save_results(res, result_save_path)\n",
    "    print(f\"Results saved to {result_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff758f97-8c31-455f-9d5e-45cf62e87a4e",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01407999-a899-42c6-85df-902f837267f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for `compare_search_algorithms`\n",
    "n_test_traces = None\n",
    "allow_intersection = True\n",
    "read_model_from_file = False\n",
    "only_return_model = False\n",
    "algorithms=['astar', 'astar_extended', 'reach']\n",
    "return_results=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c38f43-85a7-4a6d-9350-046d6fd4ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path and file names\n",
    "df_path = r'C:\\Users\\User\\Jupyter Projects\\Research_2\\Datasets\\Long_Traces'\n",
    "df_names = ['gtea_target.pkl', '50salads_target.pkl', 'breakfast_target.pkl']\n",
    "save_path = r'C:\\path\\to\\save\\directory'  # Update with your actual save path\n",
    "\n",
    "# Parameters for different datasets\n",
    "dataset_params = {\n",
    "    'gtea_target.pkl': 10,\n",
    "    '50salads_target.pkl': 10,\n",
    "    'breakfast_target.pkl': 15    \n",
    "}\n",
    "\n",
    "# Loop over each dataset\n",
    "for df_name in df_names:\n",
    "    print(f\"Processing dataset: {df_name}\")\n",
    "    \n",
    "    time_limit = 120\n",
    "    \n",
    "    # Process the pickle file\n",
    "    df = process_pickle_file(os.path.join(df_path, df_name))\n",
    "    \n",
    "    # Adjust the number of training traces based on the dataset\n",
    "    n_train_traces = dataset_params[df_name]\n",
    "    \n",
    "    # Call the compare function with the processed DataFrame\n",
    "    results = compare_search_algorithms(\n",
    "        df=df,\n",
    "        df_name=df_name,\n",
    "        n_train_traces=n_train_traces,\n",
    "        n_test_traces=n_test_traces,\n",
    "        allow_intersection=allow_intersection,\n",
    "        read_model_from_file=read_model_from_file,\n",
    "        only_return_model=only_return_model,\n",
    "        algorithms=algorithms,\n",
    "        time_limit=time_limit,  # Use the time limit set above\n",
    "        return_results=return_results\n",
    "    )\n",
    "    \n",
    "    # Save each algorithm's results to a separate pickle file\n",
    "    for alg, alg_results in results.items():\n",
    "        result_file = os.path.join(save_path, f\"{df_name.split('_')[0]}_{alg}_results.csv\")\n",
    "        \n",
    "        # Convert results to DataFrame, drop rows with all None values, and save\n",
    "        results_df = pd.DataFrame(alg_results).dropna(how='any')\n",
    "        results_df.to_csv(result_file, index=False)\n",
    "        \n",
    "        print(f\"Results for algorithm '{alg}' saved to {result_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
